from transformers import pipeline
from datasets import load_dataset
import soundfile as sf
import torch


modelo = pipeline("text-to-speech", model="microsoft/speecht5_tts", device='cuda')

embeddings_dataset = load_dataset('Matthijs/cmu-arctic-xvectors', split='validation')

print(embeddings_dataset)

speaker_embedding = torch.tensor(embeddings_dataset[7306]['xvector']).unsqueeze(0) #change index to use different voice

text = 'This audio was generated by a text to speech model from microsoft'

speech = modelo(text, forward_params={'speaker_embeddings': speaker_embedding})

sf.write('speech.wav', speech['audio'], samplerate=speech['sampling_rate'])